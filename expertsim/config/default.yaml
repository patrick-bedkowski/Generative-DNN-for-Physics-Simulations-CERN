config:
  run_name: "expertsim_train_run"  # name of the training run
wandb:
  log_experiments: False  # to initiate wandb session
  plot_images: False  # plot evaluation images to wand during training
  api_key: ""  # insert api key from wandb

model:
  architecture: "proton"  # proton or neutron
  n_experts: 3
  noise_dim: 10  # noise dimension fed to the generator model
  cond_dim: 9  # number of conditional values found in DATA_COND_PATH
  generator:
    lr_g: 1e-4
    di_strength: 1e-1  # strength of diversity reguarization
    in_strength: 1e-3  # strength of intensity reguarization
  discriminator:
    lr_d: 1e-5
  aux_reg:
    lr_a: 1e-4
    strength: 1e-3  # strength of auxilairy reguarization on the generator
  router:
    version: "router_v1"
    lr_r: 1e-4
    ed_strength: 0 #0.01  # Strength of expert distribution loss in the router loss calculation
    gan_strength: 1e-1  # Strength of generator loss in the router loss calculation
    diff_strength: 1-6  # Strength of differentiation loss on the generator loss in the router loss calculation
    util_strength: 0  # Strength of expert utilization entropy in the router loss calculation
    alb_strength: 1e-5 # 1e-3  #1e-4  # Strength of expert starvation loss in the router loss calculation
    stop_router_training_epoch: 40  # null if router should be trained until the end of the training
    alpha: 60
    min_weight: 0.2
    tau_start: 1.2  # temperature parameter for the gumbel-softmax
    tau_min: 0.8  # temperature minimum
    tau_decay: 0.985  # temperature decay rate per epoch

dataset:
  zdc_type: "proton"  # proton or neutron
  input_image_shape: [56, 30]  # shape of the images: proton [56,30], neutron [44,44]
  DATA_IMAGES_PATH: "data/data_proton_photonsum_proton_1_2312.pkl"  # path to the images data file
  DATA_COND_PATH: "data/data_cond_photonsum_proton_1_2312.pkl"
  DATA_POSITIONS_PATH: "data/data_coord_photonsum_proton_1_2312.pkl"
  MIN_INTENSITY_THRESHOLD: 1  # threshold for minimum intensity of the image pixels. For full training: keep 1
  MAX_INTENSITY_THRESHOLD: null
  read_n_samples: null  # None means all samples
  shuffle_train_test_split: True
  test_size: 0.2

train:
  batch_size: 512
  epochs: 250
  ws_threshold_model_save: 3  # Wasserstein distance threshold for saving the model
  save_experiment_data: False
  save_experiments_dir: "experiments/"  # main directory with all experiments

  # checkpoint info. Load existing training files to continue training
  checkpoint_experiment_dir: null # absolute path to the experiment folder containing dir models/ and info/ or None
  epoch_to_load: null # epoch number or None
